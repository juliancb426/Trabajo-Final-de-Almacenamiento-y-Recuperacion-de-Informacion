prefix="./data"
dataset="documents"
corpus="line.toml"
index="documents"

stop-words = "lemur-stopwords.txt"
function-words = "function-words.txt"
punctuation = "sentence-boundaries/sentence-punctuation.txt"
start-exceptions = "sentence-boundaries/sentence-start-exceptions.txt"
end-exceptions = "sentence-boundaries/sentence-end-exceptions.txt"

[[analyzers]]
method = "ngram-word"
ngram = 1
filter = [{type = "icu-tokenizer"}, {type = "lowercase"}, {type = "alpha"}, {type = "length", min = 2, max = 42}, {type = "list", file = "./data/lemur-stopwords.txt"}, {type = "empty-sentence"}]